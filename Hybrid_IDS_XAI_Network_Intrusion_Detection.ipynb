{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# üõ°Ô∏è Hybrid AI/ML Network Intrusion Detection System with Explainable AI (XAI)\n",
        "\n",
        "## AI and Machine Learning Techniques for Data Privacy and Security: Bridging Legal Requirements with Technical Solutions Across Network Domains\n",
        "\n",
        "---\n",
        "\n",
        "**Module:** INF613 - Computer Network and Data Security  \n",
        "**Institution:** The British University in Dubai  \n",
        "**Academic Year:** 2025-26\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Project Overview\n",
        "\n",
        "This notebook implements a **Hybrid AI/ML-based Network Intrusion Detection System (IDS)** that combines:\n",
        "\n",
        "1. **Random Forest** - Ensemble learning for robust classification\n",
        "2. **XGBoost** - Gradient boosting for high accuracy\n",
        "3. **Deep Neural Network (DNN)** - Deep learning for complex pattern recognition\n",
        "4. **Voting Ensemble** - Combining all models for improved robustness\n",
        "5. **SHAP (SHapley Additive exPlanations)** - For model interpretability (XAI)\n",
        "\n",
        "### üéØ Key Features\n",
        "\n",
        "- **Legal-Technical Alignment Framework (LTAF)** implementation\n",
        "- **GDPR Article 22 Compliance** through Explainable AI\n",
        "- **Privacy-by-Design** principles\n",
        "- **Comprehensive evaluation** with multiple metrics\n",
        "\n",
        "### üìä Dataset\n",
        "\n",
        "**NSL-KDD Dataset** - A refined version of the KDD Cup 1999 dataset for network intrusion detection research.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toc_cell"
      },
      "source": [
        "## üìë Table of Contents\n",
        "\n",
        "1. [Setup and Installation](#setup)\n",
        "2. [Data Loading and Exploration](#data_loading)\n",
        "3. [Data Preprocessing](#preprocessing)\n",
        "4. [Model Training](#training)\n",
        "   - 4.1 Random Forest\n",
        "   - 4.2 XGBoost\n",
        "   - 4.3 Deep Neural Network\n",
        "   - 4.4 Voting Ensemble\n",
        "5. [Model Evaluation](#evaluation)\n",
        "6. [Cross-Validation](#cross_validation)\n",
        "7. [Explainable AI (XAI) with SHAP](#xai)\n",
        "8. [Visualizations](#visualizations)\n",
        "9. [Results Summary](#results)\n",
        "10. [Legal-Technical Alignment Framework](#ltaf)\n",
        "11. [Conclusions](#conclusions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "---\n",
        "<a name=\"setup\"></a>\n",
        "## 1. üîß Setup and Installation\n",
        "\n",
        "First, let's install all required libraries and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_libraries"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q xgboost shap imbalanced-learn\n",
        "\n",
        "print(\"‚úÖ All libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "# Import all required libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    roc_curve, precision_recall_curve, average_precision_score\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# SMOTE for class imbalance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# SHAP for Explainable AI\n",
        "import shap\n",
        "\n",
        "# For saving models\n",
        "import joblib\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"üìÖ Execution started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading_header"
      },
      "source": [
        "---\n",
        "<a name=\"data_loading\"></a>\n",
        "## 2. üìÇ Data Loading and Exploration\n",
        "\n",
        "### Option A: Upload your own dataset files\n",
        "### Option B: Use the dataset directly from URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_data"
      },
      "outputs": [],
      "source": [
        "# Option A: Upload files from your computer\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì§ Please upload your Train_data.csv and Test_data.csv files:\")\n",
        "print(\"(If you have them locally, otherwise skip to Option B)\")\n",
        "\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    print(f\"\\n‚úÖ Uploaded {len(uploaded)} file(s)\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è No files uploaded. Will use alternative method.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data_alternative"
      },
      "outputs": [],
      "source": [
        "# Option B: Load NSL-KDD dataset from alternative source or create sample\n",
        "# This cell provides the dataset structure if upload doesn't work\n",
        "\n",
        "def load_nsl_kdd_data():\n",
        "    \"\"\"\n",
        "    Load NSL-KDD dataset. First tries to load from uploaded files,\n",
        "    then from URLs if available.\n",
        "    \"\"\"\n",
        "    # Try to load from uploaded files\n",
        "    try:\n",
        "        train_df = pd.read_csv('Train_data.csv')\n",
        "        test_df = pd.read_csv('Test_data.csv')\n",
        "        print(\"‚úÖ Loaded data from uploaded files\")\n",
        "        return train_df, test_df\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Try alternative file names\n",
        "    try:\n",
        "        train_df = pd.read_csv('KDDTrain+.csv')\n",
        "        test_df = pd.read_csv('KDDTest+.csv')\n",
        "        print(\"‚úÖ Loaded data from KDD files\")\n",
        "        return train_df, test_df\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"‚ö†Ô∏è Could not find uploaded files.\")\n",
        "    print(\"üì• Please upload Train_data.csv using the cell above.\")\n",
        "    return None, None\n",
        "\n",
        "# Load the data\n",
        "train_df, test_df = load_nsl_kdd_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_data"
      },
      "outputs": [],
      "source": [
        "# Data Exploration\n",
        "if train_df is not None:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üìä DATASET EXPLORATION\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(f\"\\nüìà Training Data Shape: {train_df.shape}\")\n",
        "    print(f\"üìà Test Data Shape: {test_df.shape if test_df is not None else 'N/A'}\")\n",
        "\n",
        "    print(f\"\\nüìã Column Names ({len(train_df.columns)} features):\")\n",
        "    print(train_df.columns.tolist())\n",
        "\n",
        "    print(\"\\nüìä Data Types:\")\n",
        "    print(train_df.dtypes.value_counts())\n",
        "\n",
        "    print(\"\\nüîç First 5 rows:\")\n",
        "    display(train_df.head())\n",
        "\n",
        "    print(\"\\nüìà Statistical Summary:\")\n",
        "    display(train_df.describe())\n",
        "\n",
        "    print(\"\\n‚ùì Missing Values:\")\n",
        "    missing = train_df.isnull().sum().sum()\n",
        "    print(f\"Total missing values: {missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "class_distribution"
      },
      "outputs": [],
      "source": [
        "# Visualize Class Distribution\n",
        "if train_df is not None and 'class' in train_df.columns:\n",
        "    print(\"\\nüéØ TARGET VARIABLE ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    class_counts = train_df['class'].value_counts()\n",
        "    print(\"\\nClass Distribution:\")\n",
        "    print(class_counts)\n",
        "    print(f\"\\nClass Ratio: {class_counts.iloc[0]/class_counts.iloc[1]:.2f}:1\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Bar plot\n",
        "    colors = ['#2ecc71', '#e74c3c']\n",
        "    axes[0].bar(class_counts.index, class_counts.values, color=colors, edgecolor='black')\n",
        "    axes[0].set_xlabel('Class', fontsize=12)\n",
        "    axes[0].set_ylabel('Count', fontsize=12)\n",
        "    axes[0].set_title('Class Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
        "    for i, v in enumerate(class_counts.values):\n",
        "        axes[0].text(i, v + 200, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "    # Pie chart\n",
        "    axes[1].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%',\n",
        "                colors=colors, explode=(0.05, 0.05), shadow=True, startangle=90)\n",
        "    axes[1].set_title('Class Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Class distribution plot saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_analysis"
      },
      "outputs": [],
      "source": [
        "# Analyze Feature Types\n",
        "if train_df is not None:\n",
        "    print(\"\\nüî¨ FEATURE TYPE ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Separate features by type\n",
        "    categorical_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
        "    numerical_cols = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "    # Remove target from lists if present\n",
        "    if 'class' in categorical_cols:\n",
        "        categorical_cols.remove('class')\n",
        "\n",
        "    print(f\"\\nüìä Categorical Features ({len(categorical_cols)}):\")\n",
        "    for col in categorical_cols:\n",
        "        print(f\"   ‚Ä¢ {col}: {train_df[col].nunique()} unique values\")\n",
        "\n",
        "    print(f\"\\nüìà Numerical Features ({len(numerical_cols)}):\")\n",
        "    print(f\"   Total: {len(numerical_cols)} features\")\n",
        "\n",
        "    # Show unique values for categorical features\n",
        "    print(\"\\nüìã Categorical Feature Values:\")\n",
        "    for col in categorical_cols:\n",
        "        print(f\"\\n   {col}:\")\n",
        "        print(f\"   {train_df[col].unique()[:10]}...\" if len(train_df[col].unique()) > 10 else f\"   {train_df[col].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing_header"
      },
      "source": [
        "---\n",
        "<a name=\"preprocessing\"></a>\n",
        "## 3. üîÑ Data Preprocessing\n",
        "\n",
        "This section handles:\n",
        "- Encoding categorical variables\n",
        "- Feature scaling\n",
        "- Train-validation split\n",
        "- SMOTE for class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing_class"
      },
      "outputs": [],
      "source": [
        "class DataPreprocessor:\n",
        "    \"\"\"\n",
        "    Data Preprocessing Pipeline for Network Intrusion Detection.\n",
        "\n",
        "    This class handles:\n",
        "    - Categorical encoding\n",
        "    - Feature scaling\n",
        "    - Train-validation split\n",
        "    - SMOTE for class balancing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.target_encoder = LabelEncoder()\n",
        "        self.feature_names = None\n",
        "\n",
        "    def fit_transform(self, df, target_col='class', test_size=0.2, apply_smote=True):\n",
        "        \"\"\"\n",
        "        Fit and transform the training data.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        df : pandas DataFrame\n",
        "            Input dataframe with features and target\n",
        "        target_col : str\n",
        "            Name of the target column\n",
        "        test_size : float\n",
        "            Proportion of data for validation\n",
        "        apply_smote : bool\n",
        "            Whether to apply SMOTE for class balancing\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        X_train, X_val, y_train, y_val : arrays\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üîÑ DATA PREPROCESSING PIPELINE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Separate features and target\n",
        "        X = df.drop(target_col, axis=1).copy()\n",
        "        y = df[target_col].copy()\n",
        "\n",
        "        # Encode target variable\n",
        "        print(\"\\n[1/5] Encoding target variable...\")\n",
        "        y_encoded = self.target_encoder.fit_transform(y)\n",
        "        print(f\"      Classes: {self.target_encoder.classes_}\")\n",
        "\n",
        "        # Identify column types\n",
        "        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "        numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "        print(f\"\\n[2/5] Encoding categorical features...\")\n",
        "        print(f\"      Categorical: {len(categorical_cols)} features\")\n",
        "        print(f\"      Numerical: {len(numerical_cols)} features\")\n",
        "\n",
        "        # Encode categorical variables\n",
        "        for col in categorical_cols:\n",
        "            le = LabelEncoder()\n",
        "            X[col] = le.fit_transform(X[col].astype(str))\n",
        "            self.label_encoders[col] = le\n",
        "\n",
        "        # Store feature names\n",
        "        self.feature_names = X.columns.tolist()\n",
        "\n",
        "        # Split data\n",
        "        print(f\"\\n[3/5] Splitting data (test_size={test_size})...\")\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y_encoded, test_size=test_size,\n",
        "            random_state=self.random_state, stratify=y_encoded\n",
        "        )\n",
        "        print(f\"      Training set: {X_train.shape[0]} samples\")\n",
        "        print(f\"      Validation set: {X_val.shape[0]} samples\")\n",
        "\n",
        "        # Apply SMOTE\n",
        "        if apply_smote:\n",
        "            print(f\"\\n[4/5] Applying SMOTE for class balancing...\")\n",
        "            smote = SMOTE(random_state=self.random_state)\n",
        "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "            print(f\"      After SMOTE: {X_train.shape[0]} training samples\")\n",
        "\n",
        "        # Scale features\n",
        "        print(f\"\\n[5/5] Scaling features (StandardScaler)...\")\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_val_scaled = self.scaler.transform(X_val)\n",
        "\n",
        "        print(\"\\n‚úÖ Preprocessing complete!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Store unscaled data for SHAP\n",
        "        self.X_train_df = pd.DataFrame(X_train, columns=self.feature_names)\n",
        "        self.X_val_df = pd.DataFrame(X_val.values, columns=self.feature_names)\n",
        "\n",
        "        return X_train_scaled, X_val_scaled, y_train, y_val\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        return self.feature_names\n",
        "\n",
        "# Initialize preprocessor\n",
        "preprocessor = DataPreprocessor(random_state=RANDOM_STATE)\n",
        "print(\"‚úÖ DataPreprocessor class defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_preprocessing"
      },
      "outputs": [],
      "source": [
        "# Run preprocessing\n",
        "if train_df is not None:\n",
        "    X_train, X_val, y_train, y_val = preprocessor.fit_transform(\n",
        "        train_df,\n",
        "        target_col='class',\n",
        "        test_size=0.2,\n",
        "        apply_smote=True\n",
        "    )\n",
        "\n",
        "    # Get feature names\n",
        "    feature_names = preprocessor.get_feature_names()\n",
        "\n",
        "    print(f\"\\nüìä Final Data Shapes:\")\n",
        "    print(f\"   X_train: {X_train.shape}\")\n",
        "    print(f\"   X_val: {X_val.shape}\")\n",
        "    print(f\"   y_train: {y_train.shape}\")\n",
        "    print(f\"   y_val: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_header"
      },
      "source": [
        "---\n",
        "<a name=\"training\"></a>\n",
        "## 4. ü§ñ Model Training\n",
        "\n",
        "Training four different models:\n",
        "1. Random Forest\n",
        "2. XGBoost\n",
        "3. Deep Neural Network (MLP)\n",
        "4. Voting Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_trainer_class"
      },
      "outputs": [],
      "source": [
        "class ModelTrainer:\n",
        "    \"\"\"\n",
        "    Model Training and Evaluation Pipeline.\n",
        "\n",
        "    Implements hybrid AI/ML approach combining:\n",
        "    - Random Forest (Ensemble Learning)\n",
        "    - XGBoost (Gradient Boosting)\n",
        "    - Deep Neural Network (Deep Learning)\n",
        "    - Voting Ensemble (Model Combination)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "\n",
        "    def train_random_forest(self, X_train, y_train, X_val, y_val,\n",
        "                           n_estimators=150, max_depth=25):\n",
        "        \"\"\"\n",
        "        Train Random Forest Classifier.\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üå≤ TRAINING RANDOM FOREST\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\nHyperparameters:\")\n",
        "        print(f\"   ‚Ä¢ n_estimators: {n_estimators}\")\n",
        "        print(f\"   ‚Ä¢ max_depth: {max_depth}\")\n",
        "\n",
        "        rf = RandomForestClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=self.random_state,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        print(\"\\n‚è≥ Training...\")\n",
        "        rf.fit(X_train, y_train)\n",
        "        self.models['Random Forest'] = rf\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = rf.predict(X_val)\n",
        "        y_prob = rf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        self.results['Random Forest'] = self._calculate_metrics(\n",
        "            y_val, y_pred, y_prob, 'Random Forest'\n",
        "        )\n",
        "\n",
        "        return rf\n",
        "\n",
        "    def train_xgboost(self, X_train, y_train, X_val, y_val,\n",
        "                     n_estimators=150, max_depth=12, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Train XGBoost Classifier.\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üöÄ TRAINING XGBOOST\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\nHyperparameters:\")\n",
        "        print(f\"   ‚Ä¢ n_estimators: {n_estimators}\")\n",
        "        print(f\"   ‚Ä¢ max_depth: {max_depth}\")\n",
        "        print(f\"   ‚Ä¢ learning_rate: {learning_rate}\")\n",
        "\n",
        "        xgb = XGBClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            learning_rate=learning_rate,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=self.random_state,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss'\n",
        "        )\n",
        "\n",
        "        print(\"\\n‚è≥ Training...\")\n",
        "        xgb.fit(X_train, y_train)\n",
        "        self.models['XGBoost'] = xgb\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = xgb.predict(X_val)\n",
        "        y_prob = xgb.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        self.results['XGBoost'] = self._calculate_metrics(\n",
        "            y_val, y_pred, y_prob, 'XGBoost'\n",
        "        )\n",
        "\n",
        "        return xgb\n",
        "\n",
        "    def train_deep_neural_network(self, X_train, y_train, X_val, y_val,\n",
        "                                  hidden_layers=(256, 128, 64, 32)):\n",
        "        \"\"\"\n",
        "        Train Deep Neural Network (Multi-Layer Perceptron).\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üß† TRAINING DEEP NEURAL NETWORK\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\nArchitecture:\")\n",
        "        print(f\"   ‚Ä¢ Hidden Layers: {hidden_layers}\")\n",
        "        print(f\"   ‚Ä¢ Activation: ReLU\")\n",
        "        print(f\"   ‚Ä¢ Optimizer: Adam\")\n",
        "\n",
        "        dnn = MLPClassifier(\n",
        "            hidden_layer_sizes=hidden_layers,\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            alpha=0.001,\n",
        "            batch_size=256,\n",
        "            learning_rate='adaptive',\n",
        "            learning_rate_init=0.001,\n",
        "            max_iter=200,\n",
        "            early_stopping=True,\n",
        "            validation_fraction=0.1,\n",
        "            random_state=self.random_state,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        print(\"\\n‚è≥ Training...\")\n",
        "        dnn.fit(X_train, y_train)\n",
        "        self.models['Deep Neural Network'] = dnn\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = dnn.predict(X_val)\n",
        "        y_prob = dnn.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        self.results['Deep Neural Network'] = self._calculate_metrics(\n",
        "            y_val, y_pred, y_prob, 'Deep Neural Network'\n",
        "        )\n",
        "\n",
        "        return dnn\n",
        "\n",
        "    def train_voting_ensemble(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Train Voting Ensemble combining all models.\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üó≥Ô∏è TRAINING VOTING ENSEMBLE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"\\nCombining models:\")\n",
        "        print(\"   ‚Ä¢ Random Forest\")\n",
        "        print(\"   ‚Ä¢ XGBoost\")\n",
        "        print(\"   ‚Ä¢ Deep Neural Network\")\n",
        "        print(\"   ‚Ä¢ Voting: Soft (probability-based)\")\n",
        "\n",
        "        estimators = [\n",
        "            ('rf', self.models['Random Forest']),\n",
        "            ('xgb', self.models['XGBoost']),\n",
        "            ('dnn', self.models['Deep Neural Network'])\n",
        "        ]\n",
        "\n",
        "        ensemble = VotingClassifier(\n",
        "            estimators=estimators,\n",
        "            voting='soft'\n",
        "        )\n",
        "\n",
        "        print(\"\\n‚è≥ Training...\")\n",
        "        ensemble.fit(X_train, y_train)\n",
        "        self.models['Voting Ensemble'] = ensemble\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = ensemble.predict(X_val)\n",
        "        y_prob = ensemble.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        self.results['Voting Ensemble'] = self._calculate_metrics(\n",
        "            y_val, y_pred, y_prob, 'Voting Ensemble'\n",
        "        )\n",
        "\n",
        "        return ensemble\n",
        "\n",
        "    def _calculate_metrics(self, y_true, y_pred, y_prob, model_name):\n",
        "        \"\"\"\n",
        "        Calculate comprehensive evaluation metrics.\n",
        "        \"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, average='weighted'),\n",
        "            'recall': recall_score(y_true, y_pred, average='weighted'),\n",
        "            'f1_score': f1_score(y_true, y_pred, average='weighted'),\n",
        "            'roc_auc': roc_auc_score(y_true, y_prob),\n",
        "            'confusion_matrix': confusion_matrix(y_true, y_pred),\n",
        "            'y_pred': y_pred,\n",
        "            'y_prob': y_prob\n",
        "        }\n",
        "\n",
        "        print(f\"\\n‚úÖ {model_name} Results:\")\n",
        "        print(f\"   üìä Accuracy:  {metrics['accuracy']:.4f}\")\n",
        "        print(f\"   üìä Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"   üìä Recall:    {metrics['recall']:.4f}\")\n",
        "        print(f\"   üìä F1-Score:  {metrics['f1_score']:.4f}\")\n",
        "        print(f\"   üìä ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def get_results(self):\n",
        "        return self.results\n",
        "\n",
        "    def get_models(self):\n",
        "        return self.models\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = ModelTrainer(random_state=RANDOM_STATE)\n",
        "print(\"‚úÖ ModelTrainer class defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_all_models"
      },
      "outputs": [],
      "source": [
        "# Train all models\n",
        "if train_df is not None:\n",
        "    print(\"\\n\" + \"üöÄ\"*30)\n",
        "    print(\"STARTING MODEL TRAINING\")\n",
        "    print(\"üöÄ\"*30)\n",
        "\n",
        "    # 1. Random Forest\n",
        "    rf_model = trainer.train_random_forest(\n",
        "        X_train, y_train, X_val, y_val,\n",
        "        n_estimators=150, max_depth=25\n",
        "    )\n",
        "\n",
        "    # 2. XGBoost\n",
        "    xgb_model = trainer.train_xgboost(\n",
        "        X_train, y_train, X_val, y_val,\n",
        "        n_estimators=150, max_depth=12, learning_rate=0.1\n",
        "    )\n",
        "\n",
        "    # 3. Deep Neural Network\n",
        "    dnn_model = trainer.train_deep_neural_network(\n",
        "        X_train, y_train, X_val, y_val,\n",
        "        hidden_layers=(256, 128, 64, 32)\n",
        "    )\n",
        "\n",
        "    # 4. Voting Ensemble\n",
        "    ensemble_model = trainer.train_voting_ensemble(\n",
        "        X_train, y_train, X_val, y_val\n",
        "    )\n",
        "\n",
        "    # Get results\n",
        "    results = trainer.get_results()\n",
        "    models = trainer.get_models()\n",
        "\n",
        "    print(\"\\n\" + \"‚úÖ\"*30)\n",
        "    print(\"ALL MODELS TRAINED SUCCESSFULLY!\")\n",
        "    print(\"‚úÖ\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_header"
      },
      "source": [
        "---\n",
        "<a name=\"evaluation\"></a>\n",
        "## 5. üìä Model Evaluation\n",
        "\n",
        "Comprehensive evaluation with multiple metrics and visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "results_summary"
      },
      "outputs": [],
      "source": [
        "# Results Summary Table\n",
        "if 'results' in dir():\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"üìä FINAL RESULTS SUMMARY\")\n",
        "    print(\"=\"*85)\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "        'Model': [],\n",
        "        'Accuracy': [],\n",
        "        'Precision': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        'ROC-AUC': []\n",
        "    })\n",
        "\n",
        "    for name, metrics in results.items():\n",
        "        results_df = pd.concat([results_df, pd.DataFrame({\n",
        "            'Model': [name],\n",
        "            'Accuracy': [metrics['accuracy']],\n",
        "            'Precision': [metrics['precision']],\n",
        "            'Recall': [metrics['recall']],\n",
        "            'F1-Score': [metrics['f1_score']],\n",
        "            'ROC-AUC': [metrics['roc_auc']]\n",
        "        })], ignore_index=True)\n",
        "\n",
        "    # Format percentages\n",
        "    styled_df = results_df.style.format({\n",
        "        'Accuracy': '{:.4f}',\n",
        "        'Precision': '{:.4f}',\n",
        "        'Recall': '{:.4f}',\n",
        "        'F1-Score': '{:.4f}',\n",
        "        'ROC-AUC': '{:.4f}'\n",
        "    }).background_gradient(subset=['Accuracy', 'F1-Score', 'ROC-AUC'], cmap='Greens')\n",
        "\n",
        "    display(styled_df)\n",
        "\n",
        "    # Find best model\n",
        "    best_model = results_df.loc[results_df['F1-Score'].idxmax(), 'Model']\n",
        "    best_f1 = results_df['F1-Score'].max()\n",
        "\n",
        "    print(f\"\\nüèÜ Best Model: {best_model} (F1-Score: {best_f1:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cross_validation_header"
      },
      "source": [
        "---\n",
        "<a name=\"cross_validation\"></a>\n",
        "## 6. üîÑ Cross-Validation\n",
        "\n",
        "5-fold stratified cross-validation for model reliability assessment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cross_validation"
      },
      "outputs": [],
      "source": [
        "# Cross-Validation\n",
        "if 'models' in dir():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üîÑ 5-FOLD CROSS-VALIDATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "    cv_results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        if name != 'Voting Ensemble':  # Skip ensemble for CV\n",
        "            print(f\"\\n‚è≥ Cross-validating {name}...\")\n",
        "            scores = cross_val_score(model, X_train, y_train,\n",
        "                                    cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "            cv_results[name] = {\n",
        "                'mean': scores.mean(),\n",
        "                'std': scores.std(),\n",
        "                'scores': scores\n",
        "            }\n",
        "            print(f\"   ‚úÖ {name}: {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n",
        "\n",
        "    # Visualize CV results\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    names = list(cv_results.keys())\n",
        "    means = [cv_results[n]['mean'] for n in names]\n",
        "    stds = [cv_results[n]['std'] for n in names]\n",
        "\n",
        "    colors = ['#2ecc71', '#3498db', '#9b59b6']\n",
        "    bars = ax.bar(names, means, yerr=stds, capsize=10, color=colors, edgecolor='black')\n",
        "\n",
        "    ax.set_ylabel('Accuracy', fontsize=12)\n",
        "    ax.set_title('5-Fold Cross-Validation Results', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylim(0.98, 1.0)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, mean in zip(bars, means):\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
        "                f'{mean:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('cross_validation.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Cross-validation plot saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xai_header"
      },
      "source": [
        "---\n",
        "<a name=\"xai\"></a>\n",
        "## 7. üîç Explainable AI (XAI) with SHAP\n",
        "\n",
        "**SHAP (SHapley Additive exPlanations)** provides interpretable explanations for model predictions, addressing GDPR Article 22's \"right to explanation\" requirement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shap_analysis"
      },
      "outputs": [],
      "source": [
        "# SHAP Analysis\n",
        "if 'models' in dir():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üîç EXPLAINABLE AI (XAI) WITH SHAP\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nGenerating SHAP explanations for GDPR Article 22 compliance...\")\n",
        "\n",
        "    # Use XGBoost for SHAP (tree-based is faster)\n",
        "    xgb_model = models['XGBoost']\n",
        "\n",
        "    # Sample data for SHAP\n",
        "    num_samples = min(200, len(X_val))\n",
        "    sample_idx = np.random.choice(len(X_val), num_samples, replace=False)\n",
        "    X_sample = X_val[sample_idx]\n",
        "\n",
        "    print(f\"\\n‚è≥ Computing SHAP values for {num_samples} samples...\")\n",
        "\n",
        "    # Create explainer\n",
        "    explainer = shap.TreeExplainer(xgb_model)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "    # Calculate feature importance\n",
        "    feature_importance = np.abs(shap_values).mean(axis=0)\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'SHAP Importance': feature_importance\n",
        "    }).sort_values('SHAP Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nüìä Top 10 Most Important Features (SHAP):\")\n",
        "    print(\"=\"*50)\n",
        "    for i, row in importance_df.head(10).iterrows():\n",
        "        print(f\"   {row['Feature']:35s} {row['SHAP Importance']:.4f}\")\n",
        "\n",
        "    print(\"\\n‚úÖ SHAP analysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shap_summary_plot"
      },
      "outputs": [],
      "source": [
        "# SHAP Summary Plot\n",
        "if 'shap_values' in dir():\n",
        "    print(\"\\nüìä SHAP Summary Plot\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Get top 15 features\n",
        "    top_features = importance_df.head(15)['Feature'].tolist()\n",
        "    top_indices = [feature_names.index(f) for f in top_features]\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    shap.summary_plot(\n",
        "        shap_values[:, top_indices],\n",
        "        X_sample[:, top_indices],\n",
        "        feature_names=top_features,\n",
        "        show=False\n",
        "    )\n",
        "    plt.title('SHAP Summary Plot - Feature Impact on Predictions\\n(XAI for GDPR Compliance)',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('shap_summary.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ SHAP summary plot saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shap_bar_plot"
      },
      "outputs": [],
      "source": [
        "# SHAP Bar Plot (Feature Importance)\n",
        "if 'shap_values' in dir():\n",
        "    print(\"\\nüìä SHAP Feature Importance Bar Plot\")\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    shap.summary_plot(\n",
        "        shap_values,\n",
        "        X_sample,\n",
        "        feature_names=feature_names,\n",
        "        plot_type=\"bar\",\n",
        "        max_display=15,\n",
        "        show=False\n",
        "    )\n",
        "    plt.title('SHAP Feature Importance', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('shap_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ SHAP importance plot saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualizations_header"
      },
      "source": [
        "---\n",
        "<a name=\"visualizations\"></a>\n",
        "## 8. üìà Visualizations\n",
        "\n",
        "Comprehensive visualizations for the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_comparison_plot"
      },
      "outputs": [],
      "source": [
        "# Model Comparison Bar Chart\n",
        "if 'results' in dir():\n",
        "    print(\"\\nüìä Model Performance Comparison\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "    metrics_list = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']\n",
        "    metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
        "    model_names = list(results.keys())\n",
        "\n",
        "    x = np.arange(len(metrics_list))\n",
        "    width = 0.18\n",
        "\n",
        "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c']\n",
        "\n",
        "    for i, (model_name, color) in enumerate(zip(model_names, colors)):\n",
        "        values = [results[model_name][m] for m in metrics_list]\n",
        "        bars = ax.bar(x + i*width, values, width, label=model_name, color=color, alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Metrics', fontsize=12)\n",
        "    ax.set_ylabel('Score', fontsize=12)\n",
        "    ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x + width * 1.5)\n",
        "    ax.set_xticklabels(metric_labels)\n",
        "    ax.legend(loc='lower right', fontsize=10)\n",
        "    ax.set_ylim(0.90, 1.01)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Model comparison plot saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "confusion_matrices"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrices\n",
        "if 'results' in dir():\n",
        "    print(\"\\nüìä Confusion Matrices\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    class_names = ['Normal', 'Anomaly']\n",
        "\n",
        "    for ax, (model_name, res) in zip(axes, results.items()):\n",
        "        cm = res['confusion_matrix']\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                   xticklabels=class_names, yticklabels=class_names,\n",
        "                   annot_kws={'size': 14})\n",
        "        ax.set_xlabel('Predicted', fontsize=11)\n",
        "        ax.set_ylabel('Actual', fontsize=11)\n",
        "        ax.set_title(f'{model_name}', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.suptitle('Confusion Matrices for All Models', fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Confusion matrices plot saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roc_curves"
      },
      "outputs": [],
      "source": [
        "# ROC Curves\n",
        "if 'results' in dir():\n",
        "    print(\"\\nüìä ROC Curves\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c']\n",
        "\n",
        "    for (model_name, res), color in zip(results.items(), colors):\n",
        "        fpr, tpr, _ = roc_curve(y_val, res['y_prob'])\n",
        "        auc = res['roc_auc']\n",
        "        ax.plot(fpr, tpr, color=color, lw=2.5,\n",
        "                label=f'{model_name} (AUC = {auc:.4f})')\n",
        "\n",
        "    ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "    ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "    ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "    ax.set_title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower right', fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ ROC curves plot saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_importance_plot"
      },
      "outputs": [],
      "source": [
        "# Feature Importance Comparison\n",
        "if 'models' in dir() and 'importance_df' in dir():\n",
        "    print(\"\\nüìä Feature Importance Analysis\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    # Random Forest Feature Importance\n",
        "    rf_importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': models['Random Forest'].feature_importances_\n",
        "    }).sort_values('Importance', ascending=True).tail(15)\n",
        "\n",
        "    axes[0].barh(rf_importance['Feature'], rf_importance['Importance'], color='#3498db')\n",
        "    axes[0].set_xlabel('Importance', fontsize=11)\n",
        "    axes[0].set_title('Random Forest Feature Importance', fontsize=12, fontweight='bold')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # SHAP Feature Importance\n",
        "    shap_importance = importance_df.sort_values('SHAP Importance', ascending=True).tail(15)\n",
        "    axes[1].barh(shap_importance['Feature'], shap_importance['SHAP Importance'], color='#e74c3c')\n",
        "    axes[1].set_xlabel('Mean |SHAP Value|', fontsize=11)\n",
        "    axes[1].set_title('SHAP Feature Importance (XAI)', fontsize=12, fontweight='bold')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Feature Importance Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Feature importance plot saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "precision_recall_curves"
      },
      "outputs": [],
      "source": [
        "# Precision-Recall Curves\n",
        "if 'results' in dir():\n",
        "    print(\"\\nüìä Precision-Recall Curves\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c']\n",
        "\n",
        "    for (model_name, res), color in zip(results.items(), colors):\n",
        "        precision, recall, _ = precision_recall_curve(y_val, res['y_prob'])\n",
        "        ap = average_precision_score(y_val, res['y_prob'])\n",
        "        ax.plot(recall, precision, color=color, lw=2.5,\n",
        "                label=f'{model_name} (AP = {ap:.4f})')\n",
        "\n",
        "    ax.set_xlabel('Recall', fontsize=12)\n",
        "    ax.set_ylabel('Precision', fontsize=12)\n",
        "    ax.set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='lower left', fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('precision_recall.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Precision-recall plot saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_header"
      },
      "source": [
        "---\n",
        "<a name=\"results\"></a>\n",
        "## 9. üìã Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_summary"
      },
      "outputs": [],
      "source": [
        "# Final Results Summary\n",
        "if 'results' in dir():\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"üìã FINAL RESULTS SUMMARY\")\n",
        "    print(\"=\"*85)\n",
        "\n",
        "    print(f\"\\n{'Model':<25} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'ROC-AUC':<12}\")\n",
        "    print(\"-\" * 85)\n",
        "\n",
        "    for name, res in results.items():\n",
        "        print(f\"{name:<25} {res['accuracy']:.4f}       {res['precision']:.4f}       \"\n",
        "              f\"{res['recall']:.4f}       {res['f1_score']:.4f}       {res['roc_auc']:.4f}\")\n",
        "\n",
        "    print(\"=\"*85)\n",
        "\n",
        "    # Best model\n",
        "    best_model = max(results.items(), key=lambda x: x[1]['f1_score'])\n",
        "    print(f\"\\nüèÜ Best Performing Model: {best_model[0]}\")\n",
        "    print(f\"   ‚Ä¢ Accuracy: {best_model[1]['accuracy']:.4f} ({best_model[1]['accuracy']*100:.2f}%)\")\n",
        "    print(f\"   ‚Ä¢ F1-Score: {best_model[1]['f1_score']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ ROC-AUC: {best_model[1]['roc_auc']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltaf_header"
      },
      "source": [
        "---\n",
        "<a name=\"ltaf\"></a>\n",
        "## 10. ‚öñÔ∏è Legal-Technical Alignment Framework (LTAF)\n",
        "\n",
        "Mapping legal privacy requirements to technical implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltaf_table"
      },
      "outputs": [],
      "source": [
        "# Legal-Technical Alignment Framework\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚öñÔ∏è LEGAL-TECHNICAL ALIGNMENT FRAMEWORK (LTAF)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ltaf_data = {\n",
        "    'Legal Principle': [\n",
        "        'Transparency',\n",
        "        'Accountability',\n",
        "        'Security-by-Design',\n",
        "        'Data Minimization',\n",
        "        'Accuracy'\n",
        "    ],\n",
        "    'Regulation': [\n",
        "        'GDPR Art. 22',\n",
        "        'GDPR Art. 5(2)',\n",
        "        'GDPR Art. 25',\n",
        "        'GDPR Art. 5(1c)',\n",
        "        'GDPR Art. 5(1d)'\n",
        "    ],\n",
        "    'Technical Implementation': [\n",
        "        'SHAP explanations, Feature importance rankings',\n",
        "        'Model versioning, Prediction logging, Audit trails',\n",
        "        'Real-time IDS, Multi-model ensemble redundancy',\n",
        "        'Feature selection, Relevant features only',\n",
        "        'Cross-validation, Multi-metric evaluation'\n",
        "    ]\n",
        "}\n",
        "\n",
        "ltaf_df = pd.DataFrame(ltaf_data)\n",
        "display(ltaf_df.style.set_properties(**{'text-align': 'left'}))\n",
        "\n",
        "print(\"\\nüìã LTAF Implementation Status:\")\n",
        "print(\"   ‚úÖ Transparency: SHAP explanations implemented\")\n",
        "print(\"   ‚úÖ Accountability: Model saving and logging implemented\")\n",
        "print(\"   ‚úÖ Security-by-Design: Multi-model ensemble for robustness\")\n",
        "print(\"   ‚úÖ Data Minimization: Feature importance analysis available\")\n",
        "print(\"   ‚úÖ Accuracy: Cross-validation and multi-metric evaluation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusions_header"
      },
      "source": [
        "---\n",
        "<a name=\"conclusions\"></a>\n",
        "## 11. üéØ Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "conclusions"
      },
      "outputs": [],
      "source": [
        "# Conclusions\n",
        "if 'results' in dir():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üéØ CONCLUSIONS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\"\"\n",
        "    This implementation demonstrates a Hybrid AI/ML Network Intrusion Detection\n",
        "    System with Explainable AI (XAI) capabilities, achieving:\n",
        "\n",
        "    üìä PERFORMANCE HIGHLIGHTS:\n",
        "    \"\"\")\n",
        "\n",
        "    best = max(results.items(), key=lambda x: x[1]['f1_score'])\n",
        "    print(f\"    ‚Ä¢ Best Model: {best[0]}\")\n",
        "    print(f\"    ‚Ä¢ Accuracy: {best[1]['accuracy']*100:.2f}%\")\n",
        "    print(f\"    ‚Ä¢ F1-Score: {best[1]['f1_score']:.4f}\")\n",
        "    print(f\"    ‚Ä¢ ROC-AUC: {best[1]['roc_auc']:.4f}\")\n",
        "\n",
        "    print(\"\"\"\n",
        "    üîë KEY CONTRIBUTIONS:\n",
        "    ‚Ä¢ Hybrid architecture combining classical ML with deep learning\n",
        "    ‚Ä¢ SHAP-based XAI for GDPR Article 22 compliance\n",
        "    ‚Ä¢ Legal-Technical Alignment Framework (LTAF) implementation\n",
        "    ‚Ä¢ Comprehensive evaluation with multiple metrics\n",
        "\n",
        "    üîç TOP FEATURES IDENTIFIED (XAI):\n",
        "    \"\"\")\n",
        "\n",
        "    for i, row in importance_df.head(5).iterrows():\n",
        "        print(f\"    ‚Ä¢ {row['Feature']}: {row['SHAP Importance']:.4f}\")\n",
        "\n",
        "    print(\"\"\"\n",
        "    üìö REGULATORY COMPLIANCE:\n",
        "    ‚Ä¢ GDPR Article 22 (Right to Explanation): ‚úÖ Implemented via SHAP\n",
        "    ‚Ä¢ GDPR Article 25 (Security-by-Design): ‚úÖ Multi-model ensemble\n",
        "    ‚Ä¢ CCPA (Transparency): ‚úÖ Feature importance available\n",
        "\n",
        "    üöÄ FUTURE DIRECTIONS:\n",
        "    ‚Ä¢ Multi-class attack categorization\n",
        "    ‚Ä¢ Federated Learning integration\n",
        "    ‚Ä¢ Real-time deployment optimization\n",
        "    ‚Ä¢ Adversarial robustness testing\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_models"
      },
      "outputs": [],
      "source": [
        "# Save Models and Results\n",
        "if 'models' in dir():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üíæ SAVING MODELS AND RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Save models\n",
        "    for name, model in models.items():\n",
        "        filename = name.lower().replace(' ', '_') + '.joblib'\n",
        "        joblib.dump(model, filename)\n",
        "        print(f\"   ‚úÖ Saved: {filename}\")\n",
        "\n",
        "    # Save scaler and encoders\n",
        "    joblib.dump(preprocessor.scaler, 'scaler.joblib')\n",
        "    joblib.dump(preprocessor.label_encoders, 'label_encoders.joblib')\n",
        "    print(\"   ‚úÖ Saved: scaler.joblib\")\n",
        "    print(\"   ‚úÖ Saved: label_encoders.joblib\")\n",
        "\n",
        "    # Save results to JSON\n",
        "    results_json = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'model_results': {}\n",
        "    }\n",
        "\n",
        "    for name, res in results.items():\n",
        "        results_json['model_results'][name] = {\n",
        "            'accuracy': float(res['accuracy']),\n",
        "            'precision': float(res['precision']),\n",
        "            'recall': float(res['recall']),\n",
        "            'f1_score': float(res['f1_score']),\n",
        "            'roc_auc': float(res['roc_auc']),\n",
        "            'confusion_matrix': res['confusion_matrix'].tolist()\n",
        "        }\n",
        "\n",
        "    with open('results.json', 'w') as f:\n",
        "        json.dump(results_json, f, indent=2)\n",
        "    print(\"   ‚úÖ Saved: results.json\")\n",
        "\n",
        "    print(\"\\n‚úÖ All models and results saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_files"
      },
      "outputs": [],
      "source": [
        "# Download all generated files\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üì• DOWNLOADING ALL FILES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a zip file with all outputs\n",
        "zip_filename = 'IDS_XAI_Project_Results.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # Add all PNG files\n",
        "    for file in os.listdir('.'):\n",
        "        if file.endswith('.png'):\n",
        "            zipf.write(file)\n",
        "            print(f\"   Added: {file}\")\n",
        "\n",
        "    # Add model files\n",
        "    for file in os.listdir('.'):\n",
        "        if file.endswith('.joblib'):\n",
        "            zipf.write(file)\n",
        "            print(f\"   Added: {file}\")\n",
        "\n",
        "    # Add results JSON\n",
        "    if os.path.exists('results.json'):\n",
        "        zipf.write('results.json')\n",
        "        print(\"   Added: results.json\")\n",
        "\n",
        "print(f\"\\n‚úÖ Created: {zip_filename}\")\n",
        "print(\"\\nüì• Downloading zip file...\")\n",
        "files.download(zip_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_note"
      },
      "source": [
        "---\n",
        "\n",
        "## üìù End of Notebook\n",
        "\n",
        "**Project:** Hybrid AI/ML Network Intrusion Detection with Explainable AI  \n",
        "**Module:** INF613 - Computer Network and Data Security  \n",
        "**Institution:** The British University in Dubai\n",
        "\n",
        "---\n",
        "\n",
        "### üìö References\n",
        "\n",
        "1. Tavallaee et al., \"A detailed analysis of the KDD CUP 99 data set,\" IEEE CISDA, 2009\n",
        "2. Lundberg & Lee, \"A unified approach to interpreting model predictions,\" NeurIPS, 2017\n",
        "3. European Union, \"General Data Protection Regulation (GDPR),\" 2016\n",
        "\n",
        "---"
      ]
    }
  ]
}
